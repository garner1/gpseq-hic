{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load necessary libraries and functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import coo_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "from numpy import linalg as LA\n",
    "from scipy.sparse.linalg import svds, eigs\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "def convertNansToZeros(ma):\n",
    "    nan_elements = np.flatnonzero(np.isnan(ma.data))\n",
    "    if len(nan_elements) > 0:\n",
    "        ma.data[nan_elements] = 0\n",
    "    return ma\n",
    "\n",
    "\n",
    "def convertInfsToZeros(ma):\n",
    "    inf_elements = np.flatnonzero(np.isinf(ma.data))\n",
    "    if len(inf_elements) > 0:\n",
    "        ma.data[inf_elements] = 0\n",
    "    return ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the main.sh script located in /home/garner1/Work/pipelines/gpseq-hic to generate the merged HiC and GPseq dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here we evaluate the correlation matrix of HiC contacts row\\col-normalized using GPseq, without balancing first'''\n",
    "\n",
    "datamat = np.loadtxt('/home/garner1/Work/dataset/gpseq+hic/gpseq.1M.chr1.bincount/BICRO48_TK77_10min_GG__cutsiteLoc-umiCount.transCorrected.bed.1M.chr1.dat',usecols=(0,1,5))\n",
    "\n",
    "i = datamat[:,0]\n",
    "j = datamat[:,1]\n",
    "data = datamat[:,2]\n",
    "s = max([int(max(i)), int(max(j))])\n",
    "counts = coo_matrix((data, (i, j)), shape=(s+1, s+1))\n",
    "counts = counts.todense()\n",
    "\n",
    "'''Evaluate the expected minor diagonals values'''\n",
    "expected = np.zeros(shape=[counts.shape[0]-1,])\n",
    "for offset in xrange(counts.shape[0]-1):\n",
    "    expected[offset] = np.trace(counts, offset=offset+1)/(counts.shape[0]-offset) #it is important to divide by the offdiag mean, not only the sum of the offdiag\n",
    "\n",
    "'''Normalize by minor diagonals sum'''\n",
    "for row in xrange(counts.shape[0]):\n",
    "    for col in xrange(row+1,counts.shape[1]):\n",
    "        counts[row,col] = counts[row,col]/expected[col-row-1]\n",
    "        counts[col,row] = counts[row,col]\n",
    "counts = convertNansToZeros(coo_matrix(counts)).todense()\n",
    "counts = convertInfsToZeros(coo_matrix(counts)).todense()\n",
    "\n",
    "'''Take the log'''\n",
    "counts = np.log(counts)    \n",
    "counts = convertNansToZeros(coo_matrix(counts)).todense()\n",
    "counts = convertInfsToZeros(coo_matrix(counts)).todense()\n",
    "\n",
    "'''Take the Pearson correlation matrix'''\n",
    "corrmatrix = np.corrcoef(counts)\n",
    "corrmatrix = convertNansToZeros(coo_matrix(corrmatrix)).todense()\n",
    "corrmatrix = convertInfsToZeros(coo_matrix(corrmatrix)).todense()\n",
    "\n",
    "evals, eigs = LA.eig(corrmatrix)\n",
    "\n",
    "# %matplotlib\n",
    "plt.figure(0)\n",
    "cmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\n",
    "ax = sns.heatmap(counts, center=counts.mean(),cmap=cmap)\n",
    "plt.savefig('heatmap_on.png')\n",
    "\n",
    "plt.figure(1)\n",
    "fig, ax = plt.subplots()\n",
    "y = eigs[:,0].getA1()\n",
    "y[122:143] = np.nan\n",
    "y = y-np.nanmean(y)\n",
    "ax.scatter(x=range(len(y)), y=y, c=np.sign(y), cmap=cmap)\n",
    "plt.savefig('eigvec_on.png')\n",
    "ax = sns.barplot(x=range(len(eigs[:,0].getA1())),y=eigs[:,0].getA1())\n",
    "plt.show(ax)\n",
    "\n",
    "plt.figure(2)\n",
    "cmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\n",
    "y = eigs[:,0].getA1()\n",
    "mat = np.outer(y,y)\n",
    "ax = sns.heatmap(mat, center=mat.mean(),cmap=cmap)\n",
    "plt.savefig('IeigenSpace_10min.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Here we evaluate the correlation matrix of HiC contacts with KR balancing and oe entries'''\n",
    "\n",
    "datamat = np.loadtxt('/home/garner1/Work/dataset/hic/gpseq.1M.chr1.bincount/BICRO48_TK80_on_GG__cutsiteLoc-umiCount.transCorrected.bed.1M.chr1.dat',usecols=(0,1,2))\n",
    "i = datamat[:,0]\n",
    "j = datamat[:,1]\n",
    "data = datamat[:,2]\n",
    "s = max([int(max(i)), int(max(j))])\n",
    "counts = coo_matrix((data, (i, j)), shape=(s+1, s+1))\n",
    "counts = counts.todense()\n",
    "\n",
    "'''Take the log'''\n",
    "counts = np.log(counts)    \n",
    "counts = convertNansToZeros(coo_matrix(counts)).todense()\n",
    "counts = convertInfsToZeros(coo_matrix(counts)).todense()\n",
    "\n",
    "'''Take the Pearson correlation matrix'''\n",
    "corrmatrix = np.corrcoef(counts)\n",
    "corrmatrix = convertNansToZeros(coo_matrix(corrmatrix)).todense()\n",
    "corrmatrix = convertInfsToZeros(coo_matrix(corrmatrix)).todense()\n",
    "\n",
    "evals, eigs = LA.eig(corrmatrix)\n",
    "\n",
    "plt.figure(0)\n",
    "cmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\n",
    "ax = sns.heatmap(corrmatrix, center=corrmatrix.mean(),cmap=cmap)\n",
    "plt.savefig('heatmap_KR-oe.png')\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "y = -eigs[:,0].getA1()\n",
    "y[122:143] = np.nan\n",
    "y = y-np.nanmean(y)\n",
    "ax.scatter(x=range(len(y)), y=y, c=np.sign(y), cmap=cmap)\n",
    "plt.savefig('eigvec_KR-oe.png')\n",
    "# ax = sns.barplot(x=range(len(eigs[:,0].getA1())),y=eigs[:,0].getA1())\n",
    "# plt.show(ax)\n",
    "\n",
    "plt.figure(2)\n",
    "cmap = sns.diverging_palette(220, 20, sep=20, as_cmap=True)\n",
    "y = eigs[:,0].getA1()\n",
    "mat = np.outer(y,y)\n",
    "ax = sns.heatmap(mat, center=mat.mean(),cmap=cmap)\n",
    "plt.savefig('IeigenSpace_KR-oe.png')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INPUT: combined HiC and GPseq dataset.\n",
    "\n",
    "From HiC we take the raw data (unbalanced and observed).\n",
    "\n",
    "GPseq counts are used to evaluate the indipendent probability assumption.\n",
    "\n",
    "The mutual information matrix is then constructed, keeping the information on the centrality and the time of digestion (by using different time of digestion GPseq data): \n",
    "$$ P_{HiC}(i,j)\\log \\frac{P_{HiC}(i,j)}{P_{GPseq}(i)P_{GPseq}(j)} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for chromosome in range(1,9)+range(10,22):\n",
    "    for time in ['10min','15min','30min','on']:\n",
    "        print chromosome, time\n",
    "        run = '58'\n",
    "        experiment = '*'\n",
    "#         time = duration\n",
    "        chrom = str(chromosome)\n",
    "        normalization = 'KR'\n",
    "        tipo = 'observed'\n",
    "        resolution = '1M'\n",
    "\n",
    "        directory = 'gpseq.'+resolution+'.'+normalization+'.'+tipo+'.chr'+chrom+'.bincount'\n",
    "        filename = 'BICRO'+run+'_TK'+experiment+'_'+time+'_GG__cutsiteLoc-umiCount.transCorrected.bed.'+resolution+'.chr'+chrom+'.dat'\n",
    "\n",
    "        datamat = np.loadtxt(glob.glob('/home/garner1/Work/dataset/gpseq+hic/'+directory+'/'+filename)[0],usecols=(0,1,2,3,4))\n",
    "        tags = np.loadtxt('/home/garner1/Work/dataset/gpseq+hic/tagged_with_centrality/chr'+chrom+'.bc'+run)\n",
    "\n",
    "        tags_1 = tags[tags[:,1] == 1]\n",
    "        tags_2 = tags[tags[:,1] == 2]\n",
    "        tags_3 = tags[tags[:,1] == 3]\n",
    "        tags_4 = tags[tags[:,1] == 4]\n",
    "\n",
    "        '''Define contact matrix'''\n",
    "        i = datamat[:,0]\n",
    "        j = datamat[:,1]\n",
    "        p_ij = datamat[:,2]\n",
    "        p_ij = p_ij / p_ij.sum()\n",
    "        p_i = datamat[:,3]\n",
    "        p_i = p_i / p_i.sum()\n",
    "        p_j = datamat[:,4]\n",
    "        p_j = p_j / p_j.sum()\n",
    "        s = max([int(max(i)), int(max(j))])\n",
    "        pairwise = coo_matrix((p_ij, (i, j)), shape=(s+1, s+1)).todense()\n",
    "        indip = coo_matrix((p_i*p_j, (i, j)), shape=(s+1, s+1)).todense()\n",
    "        \n",
    "        info = np.log2(pairwise / indip)\n",
    "        info = convertNansToZeros(coo_matrix(info)).todense()\n",
    "        info = convertInfsToZeros(coo_matrix(info)).todense()\n",
    "\n",
    "        counts = np.array(pairwise) * np.array(info)  #the mutual information matrix\n",
    "\n",
    "        '''Filter with respect to centrality'''\n",
    "        counts_1 = np.zeros(counts.shape)\n",
    "        counts_2 = np.zeros(counts.shape)\n",
    "        counts_3 = np.zeros(counts.shape)\n",
    "        counts_4 = np.zeros(counts.shape)\n",
    "        for row in xrange(counts.shape[0]):\n",
    "            for col in xrange(counts.shape[1]):\n",
    "                    if (row in tags_1[:,0]) and (col in tags_1[:,0]):\n",
    "                        counts_1[row,col] = counts[row,col]\n",
    "                    else:\n",
    "                        counts_1[row,col] = 0\n",
    "                    if (row in tags_2[:,0]) and (col in tags_2[:,0]):\n",
    "                        counts_2[row,col] = counts[row,col]\n",
    "                    else:\n",
    "                        counts_2[row,col] = 0\n",
    "                    if (row in tags_3[:,0]) and (col in tags_3[:,0]):\n",
    "                        counts_3[row,col] = counts[row,col]\n",
    "                    else:\n",
    "                        counts_3[row,col] = 0\n",
    "                    if (row in tags_4[:,0]) and (col in tags_4[:,0]):\n",
    "                        counts_4[row,col] = counts[row,col]\n",
    "                    else:\n",
    "                        counts_4[row,col] = 0\n",
    "        locals()['mi_'+time+'_'+'chr'+chrom] = [np.sum(counts_1),np.sum(counts_2),np.sum(counts_3),np.sum(counts_4)]\n",
    "    fig, ax = plt.subplots()\n",
    "    y = locals()['mi_10min_'+'chr'+chrom]\n",
    "    ax.scatter(x=range(len(y)),y=y,color='blue',label='10min')\n",
    "    y = locals()['mi_15min_'+'chr'+chrom]\n",
    "    ax.scatter(x=range(len(y)),y=y,color='green',label='15min')\n",
    "    y = locals()['mi_30min_'+'chr'+chrom]\n",
    "    ax.scatter(x=range(len(y)),y=y,color='red',label='30min')\n",
    "    y = locals()['mi_on_'+'chr'+chrom]\n",
    "    ax.scatter(x=range(len(y)),y=y,color='orange',label='ON')\n",
    "    ax.set_xticks([0,1,2,3])\n",
    "    ax.set_xticklabels([\"periphery\",\"II layer\",\"I layer\",\"center\"])\n",
    "    ax.set_title('Mutual information for chr'+chrom)\n",
    "    plt.legend()\n",
    "    plt.savefig('MI_chr'+chrom+'.png')\n",
    "    \n",
    "# fig, ax = plt.subplots()\n",
    "# y = np.array([mi_10min,mi_15min,mi_30min,mi_on])[:,3]\n",
    "# ax.scatter(x=range(4), y=y,color='blue')\n",
    "# ax.set_xticks([0,1,2,3])\n",
    "# ax.set_xticklabels([\"10min\",\"15min\",\"30min\",\"ON\"])\n",
    "# ax.set_title('Mutual information for chr1 at the center')\n",
    "# plt.savefig('MI_center_chr1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next block we consider HiC raw data and define independent probabilities from the marginal of the joint probability (from HiC), ie there is no GPseq data here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "for chromosome in range(1,9)+range(10,22):\n",
    "    print chromosome, time\n",
    "    run = '58'\n",
    "    experiment = '*'\n",
    "#         time = duration\n",
    "    chrom = str(chromosome)\n",
    "    normalization = 'KR'\n",
    "    tipo = 'observed'\n",
    "    resolution = '1M'\n",
    "\n",
    "    directory = 'gpseq.'+resolution+'.'+normalization+'.'+tipo+'.chr'+chrom+'.bincount'\n",
    "    filename = 'BICRO'+run+'_TK'+experiment+'_'+time+'_GG__cutsiteLoc-umiCount.transCorrected.bed.'+resolution+'.chr'+chrom+'.dat'\n",
    "\n",
    "    datamat = np.loadtxt(glob.glob('/home/garner1/Work/dataset/gpseq+hic/'+directory+'/'+filename)[0],usecols=(0,1,2,3,4))\n",
    "    tags = np.loadtxt('/home/garner1/Work/dataset/gpseq+hic/tagged_with_centrality/chr'+chrom+'.bc'+run)\n",
    "\n",
    "    tags_1 = tags[tags[:,1] == 1]\n",
    "    tags_2 = tags[tags[:,1] == 2]\n",
    "    tags_3 = tags[tags[:,1] == 3]\n",
    "    tags_4 = tags[tags[:,1] == 4]\n",
    "\n",
    "    '''Define the matrix of joint probabilities'''\n",
    "    i = datamat[:,0]\n",
    "    j = datamat[:,1]\n",
    "    p_ij = datamat[:,2]\n",
    "    p_ij = p_ij / p_ij.sum()\n",
    "    s = max([int(max(i)), int(max(j))])\n",
    "    pairwise = coo_matrix((p_ij, (i, j)), shape=(s+1, s+1)).todense()\n",
    "\n",
    "    '''Define the matrix of indipendent probabilities'''\n",
    "    marginal = pairwise.sum(axis=1) #define the normalization using HiC data\n",
    "    marginal = marginal / marginal.sum()\n",
    "    indip = np.outer(marginal,marginal)\n",
    "\n",
    "    info = np.log2(pairwise / indip)\n",
    "    info = convertNansToZeros(coo_matrix(info)).todense()\n",
    "    info = convertInfsToZeros(coo_matrix(info)).todense()\n",
    "\n",
    "    counts = np.array(pairwise) * np.array(info)  #the mutual information matrix\n",
    "\n",
    "    '''Filter with respect to centrality'''\n",
    "    counts_1 = np.zeros(counts.shape)\n",
    "    counts_2 = np.zeros(counts.shape)\n",
    "    counts_3 = np.zeros(counts.shape)\n",
    "    counts_4 = np.zeros(counts.shape)\n",
    "    for row in xrange(counts.shape[0]):\n",
    "        for col in xrange(counts.shape[1]):\n",
    "                if (row in tags_1[:,0]) and (col in tags_1[:,0]):\n",
    "                    counts_1[row,col] = counts[row,col]\n",
    "                if (row in tags_2[:,0]) and (col in tags_2[:,0]):\n",
    "                    counts_2[row,col] = counts[row,col]\n",
    "                if (row in tags_3[:,0]) and (col in tags_3[:,0]):\n",
    "                    counts_3[row,col] = counts[row,col]\n",
    "                if (row in tags_4[:,0]) and (col in tags_4[:,0]):\n",
    "                    counts_4[row,col] = counts[row,col]\n",
    "    locals()['mi_chr'+chrom] = [np.sum(counts_1),np.sum(counts_2),np.sum(counts_3),np.sum(counts_4)]\n",
    "    fig, ax = plt.subplots()\n",
    "    y = locals()['mi_chr'+chrom]\n",
    "    ax.scatter(x=range(len(y)),y=y,color='blue',label='HiC')\n",
    "    ax.set_xticks([0,1,2,3])\n",
    "    ax.set_xticklabels([\"periphery\",\"II layer\",\"I layer\",\"center\"])\n",
    "    ax.set_title('Mutual information for chr'+chrom)\n",
    "    plt.legend()\n",
    "    plt.savefig('MI_HiC_chr'+chrom+'.png')\n",
    "\n",
    "# fig, ax = plt.subplots()\n",
    "# y = np.array([mi_10min,mi_15min,mi_30min,mi_on])[:,3]\n",
    "# ax.scatter(x=range(4), y=y,color='blue')\n",
    "# ax.set_xticks([0,1,2,3])\n",
    "# ax.set_xticklabels([\"10min\",\"15min\",\"30min\",\"ON\"])\n",
    "# ax.set_title('Mutual information for chr1 at the center')\n",
    "# plt.savefig('MI_center_chr1.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
